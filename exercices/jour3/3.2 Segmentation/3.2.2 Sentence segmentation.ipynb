{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Tokenize : Exercise-1 with Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python NLTK program to split the text sentence/paragraph into a list of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_tokenization_en():\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "sent_tokenization_en.correction(sentence_tokenization_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Tokenize : Exercise-2 with Solution\n",
    "Write a Python NLTK program to tokenize sentences in languages other than English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_tokenization_fr():\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "sent_tokenization_fr.correction(sentence_tokenization_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Tokenize: Exercise-5 with Solution\n",
    "\n",
    "Write a Python NLTK program to tokenize words, sentence wise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_by_word():\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "exo_sent_by_word.correction(sentence_by_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Tokenize: Exercise-8 with Solution\n",
    "\n",
    "Write a Python NLTK program that will read a given text through each line and look for sentences. Print each sentence and divide two sentences with “==============”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex_8():\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "exo_8.correction(ex_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Tokenize: Exercise-9 with Solution\n",
    "\n",
    "Write a Python NLTK program to find parenthesized expressions in a given string and divides the string into a sequence of substrings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_parenthesis(text):\n",
    "    return \"\"\n",
    "\n",
    "exo_parenthesis.correction(split_by_parenthesis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab330c63be1774c7d4efd28485dada9f7c6eb3392ec4de9472ccb4da1daed7d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
